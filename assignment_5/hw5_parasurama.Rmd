---
title: "Problem Set 5"
author: "Prasanna Parasurama"
date: "Due: 4/12/19"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


\newcommand{\E}[1]{\ensuremath{\mathbb{E}\big[#1\big]}}
\newcommand{\Emeasure}[2]{\ensuremath{\mathbb{E}_{#1}\big[#2\big]}}

**The packages used this week are**

* ggplot2
* xtable (build tables quickly)
* data.table (data tables are computationally efficient and IMHO easier to work with)
* rdd (package for regression discontinuity designs)

```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(reticulate)
library(gridExtra)
library(rdd)
use_python("/Users/parasu/anaconda3/bin/python")
```


## Problem 1 (Coding Exercise)

The dataset for this exercise comes from a paper by Benjamin Olken entitled "Monitoring Corruption: Evidence from a Field Experiment in Indoneisa". The paper evaluates an attempt to reduce corruption in road building in Indonesia. The treatment we focus on was "accountability meetings". These meetings were held at a village level, and project officials were probed to account for how they spent project funds. Before construction began, residents in the treated villages were encouraged to attend these meetings. The dataset is called "olken.csv".

The outcome we care about is __pct.missing__, the difference between what officials claim they spent on road construction and an independent measure of expenditures. Treatment is given by __treat.invite__ such that:

\begin{align*}
  \text{treat.invite} = 
    \begin{cases}
      1 &\mbox{ if village received intervention} \\
      0 &\mbox{ if village was control }
    \end{cases}
\end{align*}

We have the following four pre-treatment covariates:

\begin{itemize}
  \item[--] head.edu : the education of the village head
  \item[--] mosques : mosques per 1000 residents
  \item[--] pct.poor : the percentage of households below the poverty line
  \item[--] total.budget : the budget for each project
\end{itemize}

We now have the following questions:

a. Create a balance table. For each pretreatment covariate, include comparisons for treated and untreated units in terms of the mean and standard deviation. Report a test, for each covariance, of the hypothesis that the difference in means between treatment conditions is zero.

```{python}
import pandas as pd
df = pd.read_csv("data/olken.csv")
pre_treat_cov = ["head.edu", "mosques", "pct.poor", "total.budget"]
df.groupby("treat.invite")[pre_treat_cov].agg({"mean": "mean", "sd": "std"}).transpose()
```

```{r}
df = read.csv("data/olken.csv")
```


```{r}
# t-test
pre_treatment_variables = c("head.edu", "mosques", "pct.poor", "total.budget")

for(v in pre_treatment_variables){
  print(v)
  print(t.test(as.formula(sprintf("%s ~ treat.invite", v)), data=df)$p.value)
}
```


b. For each covariate, plot its distribution under treatment and control (either side-by-side using facet\_grid or overlap).

```{r}
df = df %>% mutate(treat.invite = as.logical(treat.invite))


p1 = ggplot(df, aes(x=mosques, fill=treat.invite)) + geom_density(alpha=0.3)
p2 = ggplot(df, aes(x=head.edu, fill=treat.invite)) + geom_density(alpha=0.3)
p3 = ggplot(df, aes(x=pct.poor, fill=treat.invite)) + geom_density(alpha=0.3)
p4 = ggplot(df, aes(x=total.budget, fill=treat.invite)) + geom_density(alpha=0.3)

grid.arrange(p1,p2,p3,p4, nrow=2, ncol=2)
```


c. Given your answers to part a and b, do the villagers seem similar in their pre-treatment covariates?

Yes, the distributions are very similar, and t-tests fail to reject null the means between the groups are the same. 

d. Regress the treatment on the pre-treatment covariates. What do you conclude?

```{r}
selection_model = glm(treat.invite ~ mosques+ head.edu+ pct.poor+ total.budget, data=df)

summary(selection_model)
```

None of the covariates are significantly correlated with treatment, so treatment seems to be exogenous.

e. Using the difference-in-means estimator, estimate the ATE and its standard error.

```{r}

y_treated = (df %>% filter(treat.invite == TRUE))$pct.missing
y_untreated = (df %>% filter(treat.invite == FALSE))$pct.missing

# ATE
print(mean(y_treated) - mean(y_untreated))

sqrt(var(y_treated)/(length(y_treated)) + var(y_untreated)/(length(y_untreated)))


```

$$\hat{ATE}_{DM} = -0.0249$$
$$\hat{\sigma}_{\hat{ATE}_{DM}} = 0.033$$

f. Using a simple regression of outcomes on treatment, estimate the ATE and its standard error. Compare your answer in (f) to (e). Make adjustments to your regression strategy to make (f) and (e) match exactly.

```{r}
df = df %>% mutate(treat.invite = as.logical(treat.invite))
summary(lm(pct.missing ~ treat.invite, data=df))
```


g. Using the same regression from part (f), include pre-treatment covariates in your regression equation (additively and linearly). Report estimates of treatment effects and its standard error. Do you expect (g) to differ from (f) and (e)? Explain your answer.

If the pre-treatment covariates are not correlated with treatment and the outcome (i.e treatment randomization was successful) the ATE estimates will be the same.

The standard errors of the ATE in (g) will be lesser than equal to (f) and (e). 

```{r}
summary(lm(pct.missing ~ treat.invite + mosques + head.edu + pct.poor + total.budget, data=df))
```


## Problem 2 (Coding Exercise)

We will be using a dataset that was simulated from real data. Oftentimes due to privacy concerns researchers will provide simulated data from the distribution of real data. The dataset you will be using are from a tutoring program focused on math for 7th graders. The dataset is called "tests_Rd.csv". The tutoring is the treatment variable, __treat__. Tutoring was given to students based on a pretest score, __pretest__ thus the pretest score is the forcing variable. Students that received less than 215 were given a tutor. Our outcome of interest is the test score after tutoring, __posttest__. 

We also have a series of control variables:

\begin{itemize}
  \item[--] age     : age of student as of September 2010
  \item[--] gender  : 1 if student's gender is male
  \item[--] frlunch : 1 if student is eligible a free lunch
  \item[--] esol    : 1 if student has english as a second language
  \item[--] white   : 1 if student's race/ethnicity is white
  \item[--] asian   : 1 if student's race/ethnicity is asian
  \item[--] black   : 1 if student's race/ethnicity is black
  \item[--] hispanic: 1 if student's race/ethnicity is hispanic
\end{itemize}

We ask you to answer the following questions:

a. We want you to first plot the graph that justifies a sharp RD design. Plot the treatment as a function of the forcing variable. What do you see?

```{r}
df2 = read.csv("data/tests_Rd.csv")

ggplot(df2, aes(x=pretest, y=treat)) + geom_point() + geom_vline(xintercept = 215)
```

Note the sharp discontinuity at 215. 

b. We now want you to plot the graph that justifies our forcing variable. Plot the outcome as a function of the forcing variable. What do you see?
```{r}
ggplot(df2, aes(x=pretest, y=posttest)) + geom_point() + geom_vline(xintercept = 215)
```

Note the disconinuity in the trend at 215. 

c. Estimate the local average treatment effect (LATE) at the threshold using a linear model with common slopes for treated and control units (with no control variables). What are the additional assumptions required for this estimation strategy? Provide a plot of the post test scores (y-axis) and forcing variable (x-axis) in which you show the fitted curves and the underlying scatterplot of the data. Interpret your resulting estimate.

```{r}
m1 = lm(posttest~treat+pretest, data=df2)
summary(m1)
```
The main underlying assumption is that `pretest` is linear with the outcome `posttest`.

There is 10.9 point increase associated with tutoring atleast for those who around 215 cutoff threshold.  

```{r}
df2 = df2 %>% mutate(treat = as.logical(treat))
ggplot(df2, aes(pretest, posttest, color=treat)) + 
  geom_point() +
  geom_abline(slope = 0.894, intercept = 24.7) +
  geom_abline(slope = 0.894, intercept = 24.7+10.967)
  geom_vline(xintercept = 215)
```


d. Re-do c., but use the control variables that are provided in the dataset. Interpret any differences you see. 

```{r}
m2 = lm(posttest~treat+pretest+age+gender+frlunch+esol+white+asian+black+hispanic, data=df2)
summary(m2)
```

The LATE estimate is pretty much the same as (c). 

e. Use the rdd package in R to estimate the LATE at the threshold using a local linear regression with a triangular kernel. Note that the function RDestimate automatically uses the Imbens-Kalyanamaran optimal bandwidth calculation. Report your estimate for the LATE and an estimate of uncertainty.
```{r}
rde = RDestimate(posttest~pretest|age+gender+frlunch+esol+white+asian+black+hispanic,
                 data=df2,
                 cutpoint = 215)

summary(rde)
```

f. How do the estimates of the LATE at the threshold differ based on your results from parts (b) to (e)? In other words, how robust are the results to different specifications of the regression? What other types of robustness checks might be appropriate?

The results are fairly robust to different specifications. All the LATE estimates are within 2% of each other. 

Some strategies for robustness checks may include:
- Verify there is no manipulability in terms of who gets tutoring (i.e look at dsitribution of pretest scores. There should be no discontinuity)
- Verify balance between treatment and control around the threshold.

We are now going to do a series of robustness checks:

h. Plot the age variable as a function of the forcing variable. What should this graph look like for our RDD to be a valid design? What do you see? How does this relate to the covariate balance exercise we did in Problem 1?

```{r}
ggplot(df2, aes(x=pretest, y=age)) + geom_point() + geom_vline(xintercept = 215, color="red")
```

We should expect age to be balanced atleast around the threshold. It looks the age around the threshold may be a little higher for students that received tutoring. 

i. One type of placebo test is to pick arbitrary cutoffs of your forcing variable and estimate LATE's for those cutoffs. Pick 10 cutoffs and report the average LATE across those cutoffs. Defining $\hat{\tau}$ as your average LATEs, what should the null hypothesis on the population counterpart of this estimator be for our design to be valid. Feel free to use which specification you want for estimating LATE, but please specify it.

We can use RDD design with triangular kernel (RDEstimate) to estimate LATE. Our null hypothesis is that $\hat{\tau}=0$. Another null hypothesis could be that all placebo LATE estimates (except at the actual cutoff) are jointly 0. 

```{r, echo=TRUE, results="hide"}

cutoffs = seq(min(df2$pretest)+10, max(df2$pretest)-10, 10)
placebo_lates = tibble(cutoff=double(), late=double())


for(c in cutoffs){
  
  placebo = RDestimate(posttest~pretest|age+gender+frlunch+esol+white+asian+black+hispanic,
           data=df2,
           cutpoint = c)
  placebo_lates = add_row(placebo_lates, 
                          cutoff=c, 
                          late=summary(placebo)$coefficients[1, "Estimate"])
}

```

```{r}
print(placebo_lates)
mean(placebo_lates$late)
```

k. An issue with RD designs is manipulation, or sorting around the cutoff point. To assess this, plot a histogram of the forcing variable, drawing a line at the cutoff point. What would sorting around the cutoff point look like? What do you see? 

```{r}
ggplot(df2, aes(x=pretest)) + geom_histogram(bins=150) + geom_vline(xintercept = 215, color="red")
```

There is a spike right below the cutoff. There is some evidence for manipulability to get students into tutoring program. 
